{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.ticker import MultipleLocator, AutoLocator, AutoMinorLocator\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import cm\n",
    "\n",
    "import xpsi\n",
    "\n",
    "from xpsi.global_imports import _c, _G, _M_s, _dpr, gravradius, _csq, _km, _M_s, _2pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData(xpsi.Data):\n",
    "    \"\"\" Custom data container. \"\"\"\n",
    "    \n",
    "    def __init__(self, first, last, counts, phases, exposure_time):\n",
    "        \"\"\"\n",
    "        :param counts: A :class:`numpy.ndarray` of count numbers. The rows of\n",
    "                       the array must map to a contiguous subset of instrument\n",
    "                       output channels, with the zeroth row corresponding to\n",
    "                       the :attr:`first` channel, and the last row\n",
    "                       corresponding to the channel :attr:`last` minus one.\n",
    "                       The columns must map to the phases given by\n",
    "                       :obj:`phases`.\n",
    "        :param phases: A :class:`numpy.ndarray` of phase *edges* of intervals\n",
    "                       in which the *synthetic* photons arrive.\n",
    "        :param exposure_time: The total exposure time in seconds.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Execute parent initialisation code\n",
    "        super(CustomData, self).__init__(first, last)\n",
    "\n",
    "        if not isinstance(counts, np.ndarray):\n",
    "            raise TypeError('Counts object is not a ``numpy.ndarray``.')\n",
    "        else:\n",
    "            self._counts = counts\n",
    "\n",
    "        if self._counts.shape[0] != self._last - self._first:\n",
    "            raise ValueError('The number of rows must be compatible '\n",
    "                                 'with the first and last output channel '\n",
    "                                 'numbers.')\n",
    "\n",
    "        if not isinstance(phases, np.ndarray):\n",
    "            raise TypeError('Phases object is not a ``numpy.ndarray``.')\n",
    "        else:\n",
    "            self._phases = phases\n",
    "\n",
    "        self._exposure_time = exposure_time\n",
    "\n",
    "    @property\n",
    "    def exposure_time(self):\n",
    "        \"\"\" Get the total exposure time in seconds. \"\"\"\n",
    "        return self._exposure_time\n",
    "\n",
    "    @property\n",
    "    def counts(self):\n",
    "        \"\"\" Get the photon count data. \"\"\"\n",
    "        return self._counts\n",
    "\n",
    "    @property\n",
    "    def phases(self):\n",
    "        \"\"\" Get the phases. \"\"\"\n",
    "        return self._phases\n",
    "\n",
    "    @classmethod\n",
    "    def from_txt(cls, path, **kwargs):\n",
    "        \"\"\" Constructor which loads photon data from a .txt file.\n",
    "        :param str path: Path to .txt file which is converted into a\n",
    "                         two-dimensional :class:`numpy.ndarray`.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            data = np.loadtxt(path, dtype=np.double)\n",
    "        except (OSError, IOError, TypeError, ValueError):\n",
    "            print('Data file could not be loaded.')\n",
    "            raise\n",
    "\n",
    "        first = 0; last = 181\n",
    "\n",
    "        phases = np.linspace(0.0, 1.0, 33)\n",
    "\n",
    "        return cls(first, last, data, phases, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load a synthetic data set that we generated in advance, and know the fictitious exposure time for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CustomData.from_txt('../data/synthetic_realisation.dat',\n",
    "                           exposure_time = 984307.6661)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data that we aim to model. First we define some settings and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['text.usetex'] = False\n",
    "rcParams['font.size'] = 14.0\n",
    "\n",
    "def veneer(x, y, axes, lw=1.0, length=8):\n",
    "    \"\"\" Make the plots a little more aesthetically pleasing. \"\"\"\n",
    "    if x is not None:\n",
    "        if x[1] is not None:\n",
    "            axes.xaxis.set_major_locator(MultipleLocator(x[1]))\n",
    "        if x[0] is not None:\n",
    "            axes.xaxis.set_minor_locator(MultipleLocator(x[0]))\n",
    "    else:\n",
    "        axes.xaxis.set_major_locator(AutoLocator())\n",
    "        axes.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        \n",
    "    if y is not None:\n",
    "        if y[1] is not None:\n",
    "            axes.yaxis.set_major_locator(MultipleLocator(y[1]))\n",
    "        if y[0] is not None:\n",
    "            axes.yaxis.set_minor_locator(MultipleLocator(y[0]))\n",
    "    else:\n",
    "        axes.yaxis.set_major_locator(AutoLocator())\n",
    "        axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        \n",
    "    axes.tick_params(which='major', colors='black', length=length, width=lw)\n",
    "    axes.tick_params(which='minor', colors='black', length=int(length/2), width=lw)\n",
    "    plt.setp(axes.spines.values(), linewidth=lw, color='black')\n",
    "\n",
    "def plot_one_pulse(pulse, x, label=r'Counts'):\n",
    "    \"\"\" Plot a pulse resolved over a single rotational cycle. \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize = (7,7))\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[50,1])\n",
    "    ax = plt.subplot(gs[0])\n",
    "    ax_cb = plt.subplot(gs[1])\n",
    "\n",
    "    profile = ax.pcolormesh(x,\n",
    "                             np.arange(data.channel_range[1])+20,\n",
    "                             pulse,\n",
    "                             cmap = cm.magma,\n",
    "                             linewidth = 0,\n",
    "                             rasterized = True)\n",
    "\n",
    "    profile.set_edgecolor('face')\n",
    "\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel(r'Channel')\n",
    "    ax.set_xlabel(r'Phase')\n",
    "\n",
    "    cb = plt.colorbar(profile,\n",
    "                      cax = ax_cb)\n",
    "\n",
    "    cb.set_label(label=label, labelpad=25)\n",
    "    cb.solids.set_edgecolor('face')\n",
    "\n",
    "    veneer((0.05, 0.2), (None, None), ax)\n",
    "\n",
    "    plt.subplots_adjust(wspace = 0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_one_pulse(data.counts, data.phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We require a model instrument object to transform incident specific flux pulses into a form which enters directly in the sampling distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomInstrument(xpsi.Instrument):\n",
    "    \"\"\" A model of the NICER telescope response.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, channels, channel_edges, *args):\n",
    "        super(CustomInstrument, self).__init__(*args)\n",
    "        self._channels = channels\n",
    "        self._channel_edges = channel_edges\n",
    "\n",
    "    @property\n",
    "    def channels(self):\n",
    "        return self._channels\n",
    "\n",
    "    @property\n",
    "    def channel_edges(self):\n",
    "        \"\"\" Get the channel edges. \"\"\"\n",
    "        return self._channel_edges\n",
    "\n",
    "    def construct_matrix(self, p):\n",
    "        \"\"\" Implement response matrix parametrisation. \"\"\"\n",
    "\n",
    "        return self.matrix\n",
    "\n",
    "    def __call__(self, p, signal, *args):\n",
    "        \"\"\" Overwrite. \"\"\"\n",
    "\n",
    "        matrix = self.construct_matrix(p)\n",
    "\n",
    "        self._folded_signal = np.dot(matrix, signal)\n",
    "\n",
    "        return self._folded_signal\n",
    "\n",
    "    @classmethod\n",
    "    def from_response_files(cls, num_params, bounds,\n",
    "                            ARF, RMF, max_input, min_input=0,\n",
    "                            channel_edges=None):\n",
    "        \"\"\" Constructor which converts response files into :class:`numpy.ndarray`s.\n",
    "        :param str ARF: Path to ARF which is compatible with\n",
    "                                :func:`numpy.loadtxt`.\n",
    "        :param str RMF: Path to RMF which is compatible with\n",
    "                                :func:`numpy.loadtxt`.\n",
    "        :param str channel_edges: Optional path to edges which is compatible with\n",
    "                                  :func:`numpy.loadtxt`.\n",
    "        \"\"\"\n",
    "\n",
    "        if min_input != 0:\n",
    "            min_input = int(min_input)\n",
    "\n",
    "        max_input = int(max_input)\n",
    "\n",
    "        try:\n",
    "            ARF = np.loadtxt(ARF, dtype=np.double, skiprows=3)\n",
    "            RMF = np.loadtxt(RMF, dtype=np.double)\n",
    "            if channel_edges:\n",
    "                channel_edges = np.loadtxt(channel_edges, dtype=np.double, skiprows=3)[:,1:]\n",
    "        except:\n",
    "            print('A file could not be loaded.')\n",
    "            raise\n",
    "            \n",
    "        matrix = np.ascontiguousarray(RMF[min_input:max_input,20:201].T, dtype=np.double)\n",
    "\n",
    "        edges = np.zeros(ARF[min_input:max_input,3].shape[0]+1, dtype=np.double)\n",
    "\n",
    "        edges[0] = ARF[min_input,1]; edges[1:] = ARF[min_input:max_input,2]\n",
    "\n",
    "        for i in range(matrix.shape[0]):\n",
    "            matrix[i,:] *= ARF[min_input:max_input,3]\n",
    "\n",
    "        channels = np.arange(20, 201)\n",
    "\n",
    "        return cls(channels, channel_edges[20:202,-2],\n",
    "                   num_params, bounds, matrix, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NICER = CustomInstrument.from_response_files(num_params=0,\n",
    "                                             bounds=[],\n",
    "                                             ARF = '../model_data/nicer_v1.01_arf.txt',\n",
    "                                             RMF = '..//model_data/nicer_v1.01_rmf_matrix.txt',\n",
    "                                             max_input = 500,\n",
    "                                             min_input = 0,\n",
    "                                             channel_edges = '../model_data/nicer_v1.01_rmf_energymap.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NICER ``v1.01`` response matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (14,7))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "veneer((25, 100), (10, 50), ax)\n",
    "\n",
    "_ = ax.imshow(NICER.matrix,\n",
    "              cmap = cm.viridis,\n",
    "              rasterized = True)\n",
    "\n",
    "ax.set_ylabel('Channel $-\\;20$')\n",
    "_ = ax.set_xlabel('Energy interval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summed over channel subset $[20,200]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (7,7))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "veneer((0.1, 0.5), (50,250), ax)\n",
    "\n",
    "ax.plot((NICER.energy_edges[:-1]+NICER.energy_edges[1:])/2.0, np.sum(NICER.matrix, axis=0), 'k-')\n",
    "\n",
    "ax.set_ylabel('Effective area [cm$^{-2}$]')\n",
    "_ = ax.set_xlabel('Energy [keV]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xpsi.likelihoods.default_background_marginalisation import eval_marginal_likelihood\n",
    "from xpsi.likelihoods.default_background_marginalisation import precomputation\n",
    "\n",
    "class CustomPulse(xpsi.Pulse):\n",
    "    \"\"\" A custom calculation of the logarithm of the likelihood.\n",
    "    We extend the :class:`xpsi.Pulse.Pulse` class to make it callable.\n",
    "    We overwrite the body of the __call__ method. The docstring for the\n",
    "    abstract method is copied.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, workspace_intervals = 1000, epsabs = 0, epsrel = 1.0e-8,\n",
    "                 epsilon = 1.0e-3, sigmas = 10.0, **kwargs):\n",
    "        \"\"\" Perform precomputation. \"\"\"\n",
    "\n",
    "        super(CustomPulse, self).__init__(**kwargs)\n",
    "\n",
    "        try:\n",
    "            self._precomp = precomputation(self._data.counts.astype(np.int32))\n",
    "        except AttributeError:\n",
    "            print('Warning: No data... can synthesise data but cannot evaluate a '\n",
    "                  'likelihood function.')\n",
    "        else:\n",
    "            self._workspace_intervals = workspace_intervals\n",
    "            self._epsabs = epsabs\n",
    "            self._epsrel = epsrel\n",
    "            self._epsilon = epsilon\n",
    "            self._sigmas = sigmas\n",
    "\n",
    "    def __call__(self, p, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameter vector:\n",
    "        * p[0] = phase shift primary (alias for initial azimuth/phase of photosphere)\n",
    "        * p[1] = phase shift secondary\n",
    "        \"\"\"\n",
    "        self.shift = np.array(p)\n",
    "\n",
    "        self.loglikelihood, self.expected_counts, self.background_signal = \\\n",
    "                eval_marginal_likelihood(self._data.exposure_time,\n",
    "                                          self._data.phases,\n",
    "                                          self._data.counts,\n",
    "                                          self._pulse,\n",
    "                                          self._phases,\n",
    "                                          self._shift,\n",
    "                                          self._precomp,\n",
    "                                          self._workspace_intervals,\n",
    "                                          self._epsabs,\n",
    "                                          self._epsrel,\n",
    "                                          self._epsilon,\n",
    "                                          self._sigmas,\n",
    "                                          kwargs.get('llzero'))\n",
    "\n",
    "    __call__.__doc__ = xpsi.Pulse.__call__.__doc__ + __call__.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of this notebook we define a *marginal* likelihood function. That is, instead of invoking the true background model that in this case is known to us, we invoke a default treatment whereby we marginalise over a set of channel-by-channel background count-rate parameters instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote our ``__call__`` method as a wrapper for a extension module to improve speed.  The source code for the simpler case of parameter estimation when the background model is known (see ``xpsi/examples/true_background`` may be found as an [example](extensions.rst). In general, if you wish to change the model for likelihood evaluation given pulses, you can archive the Cython extensions in, e.g., the ``xpsi/likelihoods``, and compile these when X-PSI is compiled and installed (by editing the ``setup.py`` script). Alternatively, you can compile your extension elsewhere and call those compiled binaries from your custom class derived from ``xpsi.Pulse``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct and instantiate a ``pulse`` object. We give the bounds of the initial phase, a *fast* nuisance parameter, as detailed in the docstring of ``pulse``. The bounds of the background parameter have already been specified above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse = CustomPulse(tag = 'all',\n",
    "                    num_params = 2,\n",
    "                    bounds = [(-0.25, 0.75), (-0.25, 0.75)],\n",
    "                    data = data,\n",
    "                    instrument = NICER,\n",
    "                    background = None,\n",
    "                    interstellar = None,\n",
    "                    energies_per_interval = 0.5,\n",
    "                    default_energy_spacing = 'logspace',\n",
    "                    fast_rel_energies_per_interval = 0.5,\n",
    "                    workspace_intervals = 1000,\n",
    "                    adaptive_energies = False,\n",
    "                    store = True,\n",
    "                    epsrel = 1.0e-8,\n",
    "                    epsilon = 1.0e-3,\n",
    "                    sigmas = 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to build our star. The basic units for building a star are:\n",
    "\n",
    "* the [Spacetime](spacetime.rst#xpsi.Spacetime.Spacetime) class;\n",
    "* the [Photosphere](photosphere.rst#xpsi.Photosphere.Photosphere) class;\n",
    "* the [HotRegion](hotregion.rst#xpsi.HotRegion.HotRegion) class;\n",
    "* the [Elsewhere](elsewhere.rst#xpsi.Elsewhere.Elsewhere) class;\n",
    "* and four low-level user-modifiable routines for evaluation of a parametrised specific intensity model.\n",
    "\n",
    "For this demonstration we will assume that the surface radiation field *elsewhere* (other than the hot regions) can be ignored in the soft X-ray regime our model instrument is sensitive to. We need to write custom *derived* classes, and instantiate those derived classes to construct objects for our model. Let's start with the [Spacetime](spacetime.rst#xpsi.Spacetime.Spacetime) class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ambient spacetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSpacetime(xpsi.Spacetime):\n",
    "    \"\"\" A custom spacetime object.\n",
    "    \n",
    "    The coordinate rotation frequency of the star is fixed.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_params, bounds, S):\n",
    "        \"\"\"\n",
    "        :param int num_params: The number of spacetime parameters.\n",
    "        :param float S: The coordinate rotation frequency (Hz).\n",
    "        \n",
    "        \"\"\"\n",
    "        super(CustomSpacetime, self).__init__(num_params, bounds)\n",
    "\n",
    "        try:\n",
    "            self._S = float(S)\n",
    "        except TypeError:\n",
    "            raise TypeError('Coordinate spin frequency must be a ``float``.')\n",
    "        else:\n",
    "            self._Omega = 2.0 * math.pi * S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We inherited from [Spacetime](spacetime.rst#xpsi.Spacetime.Spacetime), wrote a custom initialiser, and in that initaliser executed the code in the body of the parent initaliser via a call to ``super()``. We have *fixed* the coordinate rotation frequency of the star. Let's instantiate our custom spacetime class; given that we fixed the rotation frequency, there are three spacetime parameters, details of which can be found in the documentation of the [Spacetime.update](spacetime.rst#xpsi.Spacetime.Spacetime.update) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not overwrite [Spacetime.update](spacetime.rst#xpsi.Spacetime.Spacetime.update) in our custom derived class, and thus did not add free parameters, so we set the keyword ``num_params`` to four, and define the bounds. We will assume a coordinate rotation frequency based on timing analyses of 300.0 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(0.1, 1.0), # (Earth) distance\n",
    "          (1.0, 3.0), # mass\n",
    "          (3.0 * gravradius(1.0), 16.0), # equatorial radius\n",
    "          (0.001, math.pi/2.0)] # (Earth) inclination to rotation axis\n",
    "\n",
    "spacetime = CustomSpacetime(num_params = 4, bounds = bounds, S = 300.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The photosphere and its constituent regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not *necessary* (in the current version) for us to write a custom derived class for the photosphere object, so we will simply instantiate a [Photosphere](photosphere.rst#xpsi.Photosphere.Photosphere) object. However, we first need an instance of [HotRegion](hotregion.rst#xpsi.HotRegion.HotRegion) to instantiate the photosphere, and we need to implement a low-level parametrised model for the specific intensity emergent from the photosphere in a local comoving frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the contents of the ``hot_radiation_field.pxd`` file which the X-PSI integrators use as the header file for including other C functions in the package.\n",
    "\n",
    "```cython\n",
    "cdef double eval_hotRadField(size_t THREAD,\n",
    "                             double E,\n",
    "                             double mu,\n",
    "                             const double *const VEC,\n",
    "                             void *const data) nogil\n",
    "\n",
    "cdef double eval_hotRadField_norm() nogil\n",
    "\n",
    "cdef void* init_hotRadField(size_t numThreads) nogil\n",
    "\n",
    "cdef int free_hotRadField(size_t numThreads, void *const data) nogil\n",
    "```\n",
    "\n",
    "**You are free to modify these functions in the associated** ``hot_radiation_field.pyx`` **implementation file, and you have almost complete control over the function bodies, but not the signatures.** By default the package includes an isotropic blackbody model:\n",
    "\n",
    "```cython\n",
    "#cython: cdivision=True\n",
    "#cython: boundscheck=False\n",
    "#cython: nonecheck=False\n",
    "#cython: wraparound=False\n",
    "\n",
    "from libc.math cimport exp\n",
    "\n",
    "cdef int SUCCESS = 0\n",
    "\n",
    "cdef double erg = 1.0e-7\n",
    "cdef double Planck_dist_const = 5.040366110812353e22\n",
    "    \n",
    "#----------------------------------------------------------------------->>>\n",
    "# >>> User modifiable functions.\n",
    "# >>> Note that the user is entirely free to wrap thread-safe and\n",
    "# ... non-parallel external C routines from an external library.\n",
    "# >>> Thus the bodies of the following need not be written explicitly in\n",
    "# ... the Cython language.\n",
    "#----------------------------------------------------------------------->>>\n",
    "cdef void* init_hotRadField(size_t numThreads) nogil:\n",
    "    # This function must match the free management routine free_hotRadField()\n",
    "    # in terms of freeing dynamically allocated memory. This is entirely\n",
    "    # the user's responsibility to manage.\n",
    "\n",
    "    # Return NULL if dynamic memory is not required for the model.\n",
    "    return NULL\n",
    "\n",
    "cdef int free_hotRadField(size_t numThreads, void *const data) nogil:\n",
    "    # This function must match the initialisation routine init_hotRadField()\n",
    "    # in terms of freeing dynamically allocated memory. This is entirely\n",
    "    # the user's responsibility to manage.\n",
    "    # The void pointer must be appropriately cast before memory is freed --\n",
    "    # only the user can know this at compile time.\n",
    "    # Just use free(<void*> data) iff no memory was dynamically\n",
    "    # allocated in the function:\n",
    "    #   init_local_hotRadField()\n",
    "    # because data is expected to be NULL in this case\n",
    "\n",
    "    #printf(\"\\nNo data to be freed.\")\n",
    "\n",
    "    return SUCCESS\n",
    "\n",
    "cdef double eval_hotRadField(size_t THREAD,\n",
    "                             double E,\n",
    "                             double mu,\n",
    "                             const double *const VEC,\n",
    "                             void *const data) nogil:\n",
    "    \n",
    "    cdef double temp = k_B_over_keV * pow(10.0, VEC[0])\n",
    "    \n",
    "    return E * E * E / ( exp(E / temp) - 1.0 )\n",
    "\n",
    "cdef double eval_hotRadField_norm() nogil:\n",
    "    # Surface radiation field normalisation which is independent of the\n",
    "    # parameters of the parametrised model, i.e. cell properties, energy,\n",
    "    # and angle.\n",
    "    # Writing the normalisation here reduces the number of operations required\n",
    "    # during integration.\n",
    "\n",
    "    return erg * Planck_dist_const\n",
    "```\n",
    "\n",
    "In most use-cases we need to modify these functions to enable handling of the numerical atmosphere data. An extension for such a case may be found as an [example](extensions.rst), which contains that used by [*Riley et al. (2019)*](applications.rst) to implement the ``NSX`` atmosphere computed by Wynn Ho. In general, if you wish to change the model for the parametrised local comoving surface radiation field model, you can archive the extensions in, e.g., the ``xpsi/surface_radiation_field/archive``, and completely replace the contents of ``xpsi/surface_radiation_field/hot_radiation_field.pyx`` when X-PSI is compiled and installed. Alternatively, you can compile your extension elsewhere and link it when X-PSI is installed (by editing the ``setup.py`` script), `cimporting` or `extern`ing from the appropriate `.pxd` header file(s), and calling those precompiled binaries from the functions declared in the ``xpsi/surface_radiation_field/hot_radiation_field.pxd`` header."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the atmospheric local comoving effective temperature is uniform everywhere within the hot region boundary, we can use the default value of the ``symmetry`` keyword, ``True``. All other arguments determine the numerical resolution, and have defaults which have been (somewhat arbitrarily) chosen to be result in a likelihood evaluation time of $\\mathcal{O}(1)$ s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [(0.001, math.pi - 0.001),\n",
    "          (0.001, math.pi/2.0 - 0.001),\n",
    "          (5.5, 6.5),\n",
    "          (0.001, math.pi - 0.001),\n",
    "          (0.001, math.pi/2.0 - 0.001),\n",
    "          (5.5, 6.5)]\n",
    "\n",
    "hot = xpsi.TwoHotRegions(num_params=(3,3),\n",
    "                            bounds=bounds,\n",
    "                            symmetry=True,\n",
    "                            hole=False,\n",
    "                            cede=False,\n",
    "                            concentric=False,\n",
    "                            antipodal_symmetry=False,\n",
    "                            sqrt_num_cells=32,\n",
    "                            min_sqrt_num_cells=10,\n",
    "                            max_sqrt_num_cells=64,\n",
    "                            do_fast=False,\n",
    "                            num_leaves=100,\n",
    "                            num_rays=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now instantitate the photosphere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photosphere = xpsi.Photosphere(tag = 'all', hot = hot, elsewhere = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ``tag`` the instance with the name ``'all'`` to ensure that this photosphere is matched to the ``pulse`` object with the same identification tag during likelihood evaluation; when the model defines multiple data subsets and thus multiple [Pulse](pulse.rst#xpsi.Pulse.Pulse) instances, tagging the objects in this manner is a safety guard (in particular against inadvertently wasting compute resources sampling a distribution conditional on an unintended model).\n",
    "\n",
    "We also assume that the coordinate (asymptotic) rotation frequency of the hot regions is locked to the (fixed) coordinate spin frequency of the star."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not model the surface radiation field *elsewhere*, and we thus leave the ``elsewhere`` keyword as ``None`` (the default). *Elsewhere* means on the surface, exterior to radiating hot regions that are typically expected to span a smaller angular extent; in ``v0.1``, the radiation from *elsewhere*, if explicitly computed is assumed to be time-invariant supposing the hot regions were not present. To account for radiation from *elsewhere*, a time-invariant signal is first computed, meaning an axisymmetric local comoving radiation field is assumed. The time-dependent signals from the hot regions are then computed, and modified by subtracting the specific intensity that would otherwise be generated by the local comoving radiation field from *elsewhere* (i.e., in place of the hot regions).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine the ambient spacetime, ``spacetime``, and the embedded photosphere, ``photosphere``, into a model star represented by an instance of [Star](star.rst#xpsi.Star.Star). We do not need to extend this class, so we can simply construct and instantiate a star as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star = xpsi.Star(spacetime = spacetime, photospheres = photosphere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### A callable likelihood object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Given the objects constructed above and the relevant pre-compiled low-level code, we can now construct and instantiate a *callable* likelihood object. We do not need extend (via inheritance) the [Likelihood](likelihood.rst#xpsi.Likelihood.Likelihood) class found the source code: this class simply combines all of the model objects defined above, performs some automatic operations given the properties of the those objects, and facilitates communication of those objects when it recieves a call to evaluate the likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = xpsi.Likelihood(star = star, pulses = pulse, threads=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We could in principle set the number of OpenMP threads we want to spawn in low-level functions (such as the integrator) which are parallelised, but we will leave it at the default value of ``1`` since we intend to invoke Open MPI and it is best not to experiment with the parallelisation paradigm when preparing a model as a callback for a sampling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the model objects constituting the ``likelihood`` instance, with their respective parameter numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bounds on these parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood.bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that if you want to modify the definition of the model parameter space you should restart the process of constructing a** ``likelihood`` **object, intead of manipulating existing objects.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call the ``likelihood`` object with the true model parameter values that we injected to generate the synthetic data rendered above, omitting background parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.2,\n",
    "     1.4,\n",
    "     12.5,\n",
    "     1.25,\n",
    "     1.0,\n",
    "     0.075,\n",
    "     6.2,\n",
    "     math.pi - 1.0,\n",
    "     0.2,\n",
    "     6.0,\n",
    "     0.0,\n",
    "     0.025]\n",
    "\n",
    "t = time.time()\n",
    "ll = likelihood(p)\n",
    "\n",
    "print('ll = %.8f; time = %.3f' % (ll, time.time() - t)) # ll = -26713.6136777"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the ``likelihood`` object also modified the ``pulse`` property of the ``photosphere`` object. Let's plot the ``pulse`` by summing the count-rate over output instrument channels. We first define a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pulse():\n",
    "    \"\"\" Plot hot region signals before and after telescope operation. \"\"\"\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    ax.set_ylabel('Signal [arbitrary normalisation]')\n",
    "    ax.set_xlabel('Phase [cycles]')\n",
    "    \n",
    "    temp = np.sum(pulse.pulse[0], axis=0)\n",
    "    ax.plot(pulse.phases, temp/np.max(temp), '-', color='k', lw=0.5)\n",
    "    temp = np.sum(pulse.pulse[1], axis=0)\n",
    "    ax.plot(pulse.phases, temp/np.max(temp), '-', color='r', lw=0.5)\n",
    "    \n",
    "    temp = np.sum(photosphere.pulse[0][0], axis=0)\n",
    "    ax.plot(pulse.phases, temp/np.max(temp), 'o-', color='k', lw=0.5, markersize=2)\n",
    "    temp = np.sum(photosphere.pulse[1][0], axis=0)\n",
    "    ax.plot(pulse.phases, temp/np.max(temp), 'o-', color='r', lw=0.5, markersize=2)\n",
    "    \n",
    "    veneer((0.05,0.2), (0.05,0.2), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood(p, reinitialise=True)\n",
    "_ = plot_pulse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pulse profiles with markers are the signals incident on the telescope, before operating on them with the response model. The markers, linearly spaced in phase, denote the phase resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``likelihood`` object calls the ``star.update`` method which in-turn calls the ``photosphere.embed`` method. The ``likelihood`` object then calls the ``photosphere.integrate`` method, passing the energies stored as the property ``pulse.energies``. We can do this manually if we wish to integrate pulses but not calculate likelihoods. Here we sum over incident specific photon flux pulses as an approximation to integrating over energy. Note that we do not change the ``pulse.pulses`` traced by the solid curves without markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q = [0.2,\n",
    "     1.4,\n",
    "     12.5,\n",
    "     1.0, # lower the Earth inclination\n",
    "     1.0,\n",
    "     0.075,\n",
    "     6.2,\n",
    "     math.pi - 1.0,\n",
    "     0.2,\n",
    "     6.0,\n",
    "     0.0,\n",
    "     0.025]\n",
    "\n",
    "star.update(q)\n",
    "photosphere.integrate(energies=pulse.default_energies, threads=1)\n",
    "\n",
    "_ = plot_pulse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the solid pulses without markers are unchanged from the plot a few cells above, and can be used to guide the eye to the effect of a change in Earth inclination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we print crude representations of the cell meshes spanning each hot region. The elements of a mesh cell-area array which are finite are not all identical: at the boundary of a hot region the proper area elements are smaller because of partial coverage by radiating material. The sum of all finite proper areas effectively equals the total proper area within a hot-region boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (14,7))\n",
    "\n",
    "gs = gridspec.GridSpec(1, 3, width_ratios=[50,50,1], wspace=0.2)\n",
    "ax = plt.subplot(gs[0])\n",
    "veneer((1,5), (1, 5), ax)\n",
    "\n",
    "# primary (lower colatitude) hot region\n",
    "z = hot._HotRegion__cellArea[0]/np.max(hot._HotRegion__cellArea[0])\n",
    "patches = plt.pcolormesh(z,\n",
    "                         vmin = np.min(z),\n",
    "                         vmax = np.max(z),\n",
    "                         cmap = cm.magma,\n",
    "                         linewidth = 1.0,\n",
    "                         rasterized = True,\n",
    "                         edgecolor='black')\n",
    "\n",
    "ax = plt.subplot(gs[1])\n",
    "veneer((1,5), (1, 5), ax)\n",
    "\n",
    "# secondary (higher colatitude) hot region\n",
    "z = hot.cellArea[0]/np.max(hot.cellArea[0])\n",
    "_ = plt.pcolormesh(z,\n",
    "                   vmin = np.min(z),\n",
    "                   vmax = np.max(z),\n",
    "                   cmap = cm.magma,\n",
    "                   linewidth = 1.0,\n",
    "                   rasterized = True,\n",
    "                   edgecolor='black')\n",
    "\n",
    "ax_cb = plt.subplot(gs[2])\n",
    "cb = plt.colorbar(patches,\n",
    "                  cax = ax_cb,\n",
    "                  ticks = MultipleLocator(0.2))\n",
    "\n",
    "cb.set_label(label = r'cell area (normalised by maximum)', labelpad=25)\n",
    "cb.solids.set_edgecolor('face')\n",
    "\n",
    "veneer((None, None), (0.05, None), ax_cb)\n",
    "cb.outline.set_linewidth(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the lowest colatitude row is at zero on the y-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot a pulse in two dimensions. Also note that we can interpolate the signal in phase as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xpsi.tools import phase_interpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_pulse(z, x, shift, y, ylabel, num_rotations=5.0, res=5000, cm=cm.viridis):\n",
    "    \"\"\" Helper function to plot a phase-energy pulse.\n",
    "    \n",
    "    :param array-like z:\n",
    "        A pair of *ndarray[m,n]* objects representing the signal at\n",
    "        *n* phases and *m* values of an energy variable.\n",
    "        \n",
    "    :param ndarray[n] x: Phases the signal is resolved at.\n",
    "        \n",
    "    :param tuple shift: Hot region phase parameters.\n",
    "    \n",
    "    :param ndarray[m] x: Energy values the signal is resolved at.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize = (12,6))\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[50,1], wspace=0.025)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    ax_cb = plt.subplot(gs[1])\n",
    "\n",
    "    new_phases = np.linspace(0.0, num_rotations, res)\n",
    "\n",
    "    interpolated = phase_interpolator.interpolate_pulse(new_phases,\n",
    "                                                        x,\n",
    "                                                        z[0], shift[0])\n",
    "    interpolated += phase_interpolator.interpolate_pulse(new_phases,\n",
    "                                                         x,\n",
    "                                                         z[1], shift[1])\n",
    "\n",
    "    profile = ax.pcolormesh(new_phases,\n",
    "                             y,\n",
    "                             interpolated/np.max(interpolated),\n",
    "                             cmap = cm,\n",
    "                             linewidth = 0,\n",
    "                             rasterized = True)\n",
    "\n",
    "    profile.set_edgecolor('face')\n",
    "\n",
    "    ax.set_xlim([0.0, 5.0])\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_xlabel(r'Phase')\n",
    "    veneer((0.1, 0.5), (None,None), ax)\n",
    "\n",
    "    cb = plt.colorbar(profile,\n",
    "                      cax = ax_cb,\n",
    "                      ticks = MultipleLocator(0.2))\n",
    "\n",
    "    cb.set_label(label=r'Signal (normalised by maximum)', labelpad=25)\n",
    "    cb.solids.set_edgecolor('face')\n",
    "\n",
    "    veneer((None, None), (0.05, None), ax_cb)\n",
    "    cb.outline.set_linewidth(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The incident specific flux signal, in units of photons/cm$^{2}$/s/keV as output by the source code, and then normalised to the maximum in specific flux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_pulse((photosphere.pulse[0][0], photosphere.pulse[1][0]),\n",
    "              x=pulse.phases,\n",
    "              shift=p[-2:],\n",
    "              y=pulse.default_energies,\n",
    "              ylabel=r'Energy (keV)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count rate signal in each channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_pulse((pulse.pulse[0], pulse.pulse[1]),\n",
    "              x=pulse.phases,\n",
    "              shift=p[-2:],\n",
    "              y=NICER.channels,\n",
    "              ylabel=r'Channels',\n",
    "              cm=cm.magma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use parameter vector ``q``, increase the phase resolution, and plot a single rotational pulse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot.set_phases(num_leaves = 1024)\n",
    "# the current relationship between objects requires that we reinitialise\n",
    "# if we wish to automatically communicate the update to the phases\n",
    "_ = likelihood(q, reinitialise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = pulse.pulse[0] + pulse.pulse[1]\n",
    "\n",
    "# the count rate signal is normalised with respect to the global maximum\n",
    "# over channels and phase of the joint signal from the hot regions\n",
    "plot_one_pulse(temp/np.max(temp), pulse.phases, r'Signal (normalised by maximum)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate over a monotonically increasing set of values of the hot-region angular radius. Note that we use the keyword ``threads`` to directly instruct the low-level routines how many OpenMP threads to spawn to accelerate the computation. Usually the ``likelihood`` object instructs the low-level routines how many threads to spawn, based on it's ``thread`` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood.threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we are not currently using the ``likelihood`` object as a callback function passed to posterior sampling software (which parallelises efficiently using Open MPI), we can safely spawn additional worker threads for pulse integration; if likelihood evaluations are parallelised in an Open MPI environment on the other hand, one risks *losing* efficiency by spawning worker threads for likelihood evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylabel('Photons/cm$^2$/s/keV (normalised by maxima)')\n",
    "ax.set_xlabel('Phase [cycles]')\n",
    "\n",
    "hot.set_phases(num_leaves = 256)\n",
    "\n",
    "# let's play with the angular radius of the primary hot region\n",
    "angular_radii = np.linspace(0.01, 1.0, 10)\n",
    "\n",
    "q = list(p) # copy\n",
    "\n",
    "for angular_radius in angular_radii:\n",
    "    q[5] = angular_radius\n",
    "    star.update(q, threads=3)\n",
    "    photosphere.integrate(energies=pulse.energies, threads=3)\n",
    "    temp = np.sum(photosphere.pulse[1][0], axis=0) + np.sum(photosphere.pulse[0][0], axis=0)\n",
    "    _ = ax.plot(hot.phases_in_cycles, temp/np.max(temp), 'k-', lw=0.5)\n",
    "\n",
    "q = list(p)\n",
    "q[3] = 1.0 # change inclination\n",
    "    \n",
    "for angular_radius in angular_radii:\n",
    "    q[5] = angular_radius\n",
    "    star.update(q, threads=3)\n",
    "    photosphere.integrate(energies=pulse.energies, threads=3)\n",
    "    temp = np.sum(photosphere.pulse[1][0], axis=0) + np.sum(photosphere.pulse[0][0], axis=0)\n",
    "    _ = ax.plot(hot.phases_in_cycles, temp/np.max(temp), 'r-', lw=0.5)\n",
    "\n",
    "q = list(p)\n",
    "q[3] = 0.5\n",
    "\n",
    "for angular_radius in angular_radii:\n",
    "    q[5] = angular_radius\n",
    "    star.update(q, threads=3)\n",
    "    photosphere.integrate(energies=pulse.energies, threads=3)\n",
    "    temp = np.sum(photosphere.pulse[1][0], axis=0) + np.sum(photosphere.pulse[0][0], axis=0)\n",
    "    _ = ax.plot(hot.phases_in_cycles, temp/np.max(temp), 'b-', lw=0.5)\n",
    "    \n",
    "veneer((0.05,0.2), (0.05,0.2), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now construct a callable object representing a joint prior density distribution on the space $\\mathbb{R}^{d}$. We need to extend the base class to implement our distribution, which with respect to some parameters is separable, but for others it is *uniform* on a joint space, and compactly supported according to non-trivial constraint equations.\n",
    "\n",
    "As an example gravitational mass and equatorial radius: a joint constraint is imposed to assign zero density to stars which are *too* compact (the polar radius of the rotationally deformed stellar 2-surface is too small)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPrior(xpsi.Prior):\n",
    "    \"\"\" A custom (joint) prior distribution.\n",
    "    \n",
    "    Source: Fictitious\n",
    "    Model variant: ST-U\n",
    "        Two single-temperature, simply-connected circular hot regions with\n",
    "        unshared parameters.\n",
    "    \n",
    "    Parameter vector:\n",
    "    \n",
    "        * p[0] = distance (kpc)\n",
    "        * p[1] = (rotationally deformed) gravitational mass (solar masses)\n",
    "        * p[2] = coordinate equatorial radius (km)\n",
    "        * p[3] = inclination of Earth to rotational axis (radians)\n",
    "        * p[4] = primary region centre colatitude (radians)\n",
    "        * p[5] = primary region angular radius (radians)\n",
    "        * p[6] = primary region log10(local comoving blackbody temperature [K])\n",
    "        * p[7] = secondary region centre colatitude (radians)\n",
    "        * p[8] = secondary region angular radius (radians)\n",
    "        * p[9] = secondary region log10(local comoving blackbody temperature [K])\n",
    "        * p[10] = primary region phase shift (cycles); (alias for initial azimuth, periodic)\n",
    "        * p[11] = secondary region phase shift (cycles)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, bounds, spacetime):\n",
    "        \"\"\"\n",
    "        :param obj spacetime:\n",
    "            Bit of a hack to access spacetime properties for defining\n",
    "            the support of the prior.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Execute abstract parent initialiser\n",
    "        super(CustomPrior, self).__init__(bounds)\n",
    "\n",
    "        assert isinstance(spacetime, xpsi.Spacetime),\\\n",
    "                'Invalid type for ambient spacetime object.'\n",
    "\n",
    "        self._spacetime = spacetime\n",
    "\n",
    "    def __call__(self, p):\n",
    "        \"\"\" Evaluate distribution at :obj:`p`.\n",
    "        \n",
    "        :param list p: Model parameters values.\n",
    "        \n",
    "        :returns: Logarithm of the distribution evaluated at :obj:`p`.\n",
    "        \n",
    "        \"\"\"\n",
    "        for i, b in enumerate(self._bounds):\n",
    "            if None not in b:\n",
    "                if not b[0] <= p[i] <= b[1]:                                                                                                        \n",
    "                    return -np.inf\n",
    "        \n",
    "        i = self._spacetime.num_params\n",
    "        # update and access spacetime properties\n",
    "        self._spacetime.update(*p[:i])\n",
    "\n",
    "        # based on contemporary EOS theory\n",
    "        if not self._spacetime.R <= 16.0*_km:\n",
    "            return -np.inf\n",
    "\n",
    "        # photon sphere\n",
    "        if not 1.5 < self._spacetime.R_r_s:\n",
    "            return -np.inf\n",
    "\n",
    "        epsilon = self._spacetime.epsilon\n",
    "        zeta = self._spacetime.zeta\n",
    "        mu = math.sqrt(-1.0 / (3.0 * epsilon * (-0.788 + 1.030 * zeta)))\n",
    "\n",
    "        # 2-surface cross-section have a single maximum in |z|\n",
    "        # i.e., an elliptical surface; minor effect on support\n",
    "        if mu < 1.0:\n",
    "            return -np.inf\n",
    "\n",
    "        R_p = 1.0 + epsilon * (-0.788 + 1.030 * zeta)\n",
    "        \n",
    "        # polar radius causality for ~static star (static ambient spacetime)\n",
    "        # if R_p < 1.5 / self._spacetime.R_r_s:\n",
    "        #     return -np.inf\n",
    "\n",
    "        # limit polar radius to try to exclude deflections >= \\pi radians\n",
    "        if R_p < 1.76 / self._spacetime.R_r_s:\n",
    "            return -np.inf\n",
    "        \n",
    "        # enforce order in hot region colatitude\n",
    "        if p[4] > p[7]:\n",
    "            return -np.inf\n",
    "\n",
    "        theta_p = p[4]\n",
    "        phi = (p[10] - 0.5 - p[11]) * _2pi\n",
    "        rho_p = p[5]\n",
    "\n",
    "        theta_s = p[7]\n",
    "        rho_s = p[8]\n",
    "\n",
    "        ang_sep = xpsi.HotRegion._psi(theta_s, phi, theta_p)\n",
    "\n",
    "        # hot regions cannot overlap\n",
    "        if ang_sep < rho_p + rho_s:\n",
    "            return -np.inf\n",
    "\n",
    "        return 0.0\n",
    "\n",
    "    def inverse_sample(self, hypercube):\n",
    "        \"\"\" Draw sample uniformly from the distribution via inverse sampling. \"\"\"\n",
    "        \n",
    "        p = super(CustomPrior, self).inverse_sample(hypercube)\n",
    "\n",
    "        # distance\n",
    "        p[0] = truncnorm.ppf(hypercube[0], -2.0, 7.0, loc=0.3, scale=0.1)\n",
    "\n",
    "        return p\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(p):\n",
    "        \"\"\" A transformation for post-processing. \"\"\"\n",
    "\n",
    "        if not isinstance(p, list):\n",
    "            p = list(p)\n",
    "        \n",
    "        # compactness ratio M/R_eq\n",
    "        p += [gravradius(p[1]) / p[2]]\n",
    "        \n",
    "        if p[10] < 0.0:\n",
    "            tempp = p[10] + 1.0\n",
    "        else:\n",
    "            tempp = p[10]\n",
    "        \n",
    "        temps = 0.5 + p[11]\n",
    "        \n",
    "        if temps > 1.0:\n",
    "            temps = temps - 1.0\n",
    "        \n",
    "        # phase separation\n",
    "        if temps >= tempp:\n",
    "            p += [temps - tempp]\n",
    "        else:\n",
    "            p += [1.0 - tempp + temps]\n",
    "        \n",
    "        # angle combinations\n",
    "        p += [p[3] - p[4]]\n",
    "        p += [p[3] + p[4]]\n",
    "        p += [p[3] - p[7]]\n",
    "\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now construct and instantiate a callable ``prior`` object, passing the bounds from the ``likelihood`` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = CustomPrior(bounds = likelihood.bounds, spacetime = spacetime)\n",
    "\n",
    "prior(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``prior.inverse_sample()`` method can be used to initialise the ensemble of walkers evolved by [emcee](http://emcee.readthedocs.io/en/latest/), and is required by [MultiNest](https://github.com/farhanferoz/MultiNest) to uniformly sample from the prior distribution and transform it into a posterior distribution. Let's call the method, passing a vector of pseudorandom numbers drawn when each is drawn from a uniform distribution on the interval $[0,1)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.inverse_sample(np.random.rand(prior.ndims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Density and support checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's draw samples from the prior and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps, _ = prior.draw(int(1e4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samps(samps, x, y, xlabel, ylabel, s=1.0, color='k', **kwargs):\n",
    "    \"\"\" Plot samples as 2D scatter plot. \"\"\"\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(samps[:,x], samps[:,y], s=s, color=color, **kwargs)\n",
    "    veneer(None, None, ax)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    return plt.gca()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first plot the $(M, R_{\\rm eq})$ samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_samps(samps, 2, 1, r'$R_{\\rm eq}$ [km]', r'$M$ [M$_{\\odot}$]')\n",
    "\n",
    "# the Schwarzschild photon sphere R_eq = 1.5 x r_s(M)\n",
    "ax.plot(3.0*gravradius(np.linspace(1.0,3.0,100)), np.linspace(1.0,3.0,100), 'k-')\n",
    "\n",
    "# R_eq = 1.76 x r_s(M)\n",
    "_ = ax.plot(2.0*1.76*gravradius(np.linspace(1.0,3.0,100)), np.linspace(1.0,3.0,100), 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the prior support is defined with a constraint that the polar radius $R_{\\rm p}(R_{\\rm eq}, M, \\Omega)\\geq 1.76r_{s}(M)$, which is why there is a region devoid of samples between the prior support and the dashed line $R_{\\rm eq} = 1.76r_s(M)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now plot the hot region (circular spot) colatitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plot_samps(samps, 4, 7, r'$\\Theta_{p}$ [radians]', r'$\\Theta_{s}$ [radians]')\n",
    "\n",
    "# enforce colatitude order to distinguish hot regions as primary and secondary\n",
    "_ = ax.plot(np.array([0.0,math.pi]), np.array([0.0,math.pi]), 'r--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the samples, marginalised over other region geometry parameters, are sparser when both hot regions approach the poles because we exclude overlapping configurations from the prior support. This is because the hot regions are by convention defined as disjoint, and cannot merge. If one wanted a more complex hot region, one would not invoke multiple hot regions that are permitted to overlap, but one would instead handle the extra complexity within the ``HotRegion`` class or a subclass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the angular radii of the spots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_samps(samps, 5, 8, r'$\\zeta_{p}$ [radians]', r'$\\zeta_{s}$ [radians]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the prior density is greater for hot regions that subtend smaller solid angles at the centre of the star, which also derives from the non-overlapping criterion for prior support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take a look at the phases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_samps(samps, -2, -1, r'$\\phi_{p}$ [cycles]', r'$\\phi_{s}$ [cycles]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that again because the hot regions cannot overlap, rarefaction occurs in the vicinity of lines of minimal phase separation. Note that the boundaries are all periodic, so this pattern tesselates. Because we implemented a transformation in our ``CustomPrior`` subclass, we can actually draw the samples and transform them, which is useful in post-processing contexts. We defined the intervals ``[-0.25, 0.75]`` for the inverse sampling so that the posterior mode(s) will not be near a boundary.  The nested sampling algorithm can handle periodic boundaries by defining ``wrapped`` parameters; however, this can be trivially avoided altogether by rough inspection of the phases of the subpulses in the data, which we can see above are at around $-0.1$ and $0.4$ given the respective ground truth phases of $\\phi_{p}=0.0$ and $\\phi_{s}=0.025$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations for the purpose of likelihood evaluation must be handled in the ``inverse_sample`` method of an instance of the ``Prior`` class, but additional transformations that *extend* the parameter vector are written in ``transform`` method which may or may not be defined as *static* (as in the ``Prior`` class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to transform automatically upon drawing the samples, thereby extending the parameter vectors passed to the ``__call__`` method (so be careful with wrap-around indices when evaluating prior support conditions), we would do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samps_plus_transformed, _ = prior.draw(int(1e4), transform=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We defined a transformation from the hot region centre phases to the phase separation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_samps(samps_plus_transformed, -7, -4, r'$\\phi_{p}$ [cycles]', r'$\\Delta\\phi$ [cycles]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the rarefaction occurs for $\\Delta\\phi\\sim0.0=1.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The marginal one-dimensional prior distributions are overplotted, by the [PostProcessing](postprocessing.rst) module, with the posterior distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to carefully inspect joint prior samples for pairs of parameters before commencing a sampling run, especially if there is a non-trivial constraint equation imposed on the prior support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have constructed and instantiated both a callable ``likelihood`` object and a callable ``prior`` object. We could proceed, for example, to apply the open-source sampler [emcee](http://emcee.readthedocs.io/en/latest/) to the joint posterior distribution proportional to the product of the (exponentiated) calls to the ``likelihood`` and ``prior`` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble MCMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prove that the objects constructed above can be fed to the ``emcee`` sampler, let's run a number of iterations using a single Python process. We will initialise the ensemble by drawing from a multivariate Gaussian with mean vector equal to the ground truth vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "std = [0.01,\n",
    "         0.05,\n",
    "         0.1,\n",
    "         0.01,\n",
    "         0.05,\n",
    "         0.0025,\n",
    "         0.01,\n",
    "         0.05,\n",
    "         0.05,\n",
    "         0.01,\n",
    "         0.01,\n",
    "         0.01]\n",
    "\n",
    "runtime_params = {'resume': False,\n",
    "                  'root_dir': './',\n",
    "                  'nwalkers': 50,\n",
    "                  'nsteps': 100,\n",
    "                  'walker_dist_moments': zip(p, std)} #  if resume then ``None``\n",
    "\n",
    "hot.set_phases(num_leaves = 100)\n",
    "likelihood.threads = 3\n",
    "likelihood.reinitialise()\n",
    "\n",
    "# Use MPI=False for testing purposes\n",
    "backend = xpsi.Sample.ensemble(likelihood, prior,\n",
    "                               MPI=False, **runtime_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the docs/source directory\n",
    "#!rm samples.h5; rm -r old_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could also try initialising the ensemble by inverse sampling the joint prior distribution.\n",
    "\n",
    "Let's quickly plot the evolution of the ensemble Markov chains to prove that the sampling process commenced and is behaving in a somewhat reasonable manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    backend\n",
    "except NameError:\n",
    "    import emcee\n",
    "    backend = emcee.backends.HDFBackend('samples.h5')\n",
    "    \n",
    "chain = backend.get_chain()\n",
    "\n",
    "labels = [r'$D$',\n",
    "          r'$M$',\n",
    "          r'$R_{\\rm eq}$',\n",
    "          r'$i$',\n",
    "          r'$\\Theta_{p}$',\n",
    "          r'$\\zeta_{p}$',\n",
    "          r'$T_{p}$',\n",
    "          r'$\\Theta_{s}$',\n",
    "          r'$\\zeta_{s}$',\n",
    "          r'$T_{s}$',\n",
    "          r'$\\phi_{p}$',\n",
    "          r'$\\phi_{s}$']\n",
    "\n",
    "fig = plt.figure(figsize=(8,32))\n",
    "          \n",
    "gs = gridspec.GridSpec(12, 1, hspace=0.15)\n",
    "          \n",
    "for i in range(len(labels)):\n",
    "    ax = plt.subplot(gs[i,0])\n",
    "    ax.set_ylabel(labels[i])\n",
    "    for j in range(50):\n",
    "        plt.plot(chain[:,j,i], 'k-', lw=0.5, alpha=0.5)\n",
    "    if i < 11:\n",
    "        ax.tick_params(axis='x', labelbottom=False)\n",
    "        plt.setp(ax.get_yticklabels()[0], visible=False)\n",
    "        plt.setp(ax.get_yticklabels()[-1], visible=False)\n",
    "    else: ax.set_xlabel('Steps')\n",
    "    veneer((250, 1000), None, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chains rendered in the documentation were run on a desktop machine in about a day of wall-time. It is visually discernable that the ensemble distribution has not yet evolved to a stationary state: a rigourous application of ensemble MCMC would cover convergence criteria, auto-correlation, and examination of sensitivity to initial conditions and the transition kernel. In fact, based on the analysis with nested sampling on path ``xpsi/examples/default_background``, we know that the posterior mode in the vicinity of the above ensemble is rather non-linear in the space being sampled, so ensemble MCMC may require *many* steps in order to argue for convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interface with the nested sampler MultiNest in a similar manner, by defining some runtime settings, and then passing those settings together with ``likelihood`` and ``prior`` objects to a wrapper from the [Sample](sample.rst) module. We will run the sampler for a specified number (1000) of nested replacements (iterations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment variable ``LD_LIBRARY_PATH`` must be set before launching Jupyter as follows:\n",
    "    \n",
    "    $ export LD_LIBRARY_PATH=<path/to/multinest>/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_params = {'resume': False,\n",
    "                  'importance_nested_sampling': False,\n",
    "                  'multimodal': False,\n",
    "                  'n_clustering_params': None,\n",
    "                  'outputfiles_basename': './nsrun/run',\n",
    "                  'n_iter_before_update': 50,\n",
    "                  'n_live_points': 50,\n",
    "                  'sampling_efficiency': 0.8,\n",
    "                  'const_efficiency_mode': False,\n",
    "                  'wrapped_params': [0,0,0,0,0,0,0,0,0,0,1,1],\n",
    "                  'evidence_tolerance': 0.5,\n",
    "                  'max_iter': 1000,\n",
    "                  'verbose': True}\n",
    "\n",
    "likelihood.threads=4\n",
    "# NB: the likelihood object needs to know about the prior for nested sampling:\n",
    "likelihood.prior = prior\n",
    "\n",
    "xpsi.Sample.nested(likelihood, prior, **runtime_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verbose output of the MultiNest program is by default directed to the host terminal session. Instead of trying to redirect that output to that of the above cell, we simply copy and paste the output from the terminal below:\n",
    "\n",
    "    *****************************************************\n",
    "    MultiNest v3.11\n",
    "    Copyright Farhan Feroz & Mike Hobson\n",
    "    Release Apr 2018\n",
    "\n",
    "    no. of live points =  100\n",
    "\n",
    "    dimensionality =   12\n",
    "    *****************************************************\n",
    "    Starting MultiNest\n",
    "    generating live points\n",
    "     live points generated, starting sampling\n",
    "    Acceptance Rate:                        0.724638\n",
    "    Replacements:                                100\n",
    "    Total Samples:                               138\n",
    "    Nested Sampling ln(Z):            **************\n",
    "    Acceptance Rate:                        0.649351\n",
    "    Replacements:                                150\n",
    "    Total Samples:                               231\n",
    "    Nested Sampling ln(Z):            -116670.287917\n",
    "    Acceptance Rate:                        0.569801\n",
    "    Replacements:                                200\n",
    "    Total Samples:                               351\n",
    "    Nested Sampling ln(Z):            -115291.669431\n",
    "    Acceptance Rate:                        0.449640\n",
    "    Replacements:                                250\n",
    "    Total Samples:                               556\n",
    "    Nested Sampling ln(Z):            -108499.449911\n",
    "    Acceptance Rate:                        0.408719\n",
    "    Replacements:                                300\n",
    "    Total Samples:                               734\n",
    "    Nested Sampling ln(Z):             -95430.022790\n",
    "    Acceptance Rate:                        0.367261\n",
    "    Replacements:                                350\n",
    "    Total Samples:                               953\n",
    "    Nested Sampling ln(Z):             -77360.112633\n",
    "    Acceptance Rate:                        0.319744\n",
    "    Replacements:                                400\n",
    "    Total Samples:                              1251\n",
    "    Nested Sampling ln(Z):             -66119.380404\n",
    "    Acceptance Rate:                        0.263930\n",
    "    Replacements:                                450\n",
    "    Total Samples:                              1705\n",
    "    Nested Sampling ln(Z):             -57607.930990\n",
    "    Acceptance Rate:                        0.213675\n",
    "    Replacements:                                500\n",
    "    Total Samples:                              2340\n",
    "    Nested Sampling ln(Z):             -53505.956949\n",
    "    Acceptance Rate:                        0.173119\n",
    "    Replacements:                                550\n",
    "    Total Samples:                              3177\n",
    "    Nested Sampling ln(Z):             -50428.177797\n",
    "    Acceptance Rate:                        0.147893\n",
    "    Replacements:                                600\n",
    "    Total Samples:                              4057\n",
    "    Nested Sampling ln(Z):             -47108.755667\n",
    "    Acceptance Rate:                        0.132653\n",
    "    Replacements:                                650\n",
    "    Total Samples:                              4900\n",
    "    Nested Sampling ln(Z):             -43437.007007\n",
    "    Acceptance Rate:                        0.125381\n",
    "    Replacements:                                700\n",
    "    Total Samples:                              5583\n",
    "    Nested Sampling ln(Z):             -39888.092691\n",
    "    Acceptance Rate:                        0.113533\n",
    "    Replacements:                                750\n",
    "    Total Samples:                              6606\n",
    "    Nested Sampling ln(Z):             -36841.337131\n",
    "    Acceptance Rate:                        0.100251\n",
    "    Replacements:                                800\n",
    "    Total Samples:                              7980\n",
    "    Nested Sampling ln(Z):             -34450.919514\n",
    "    Acceptance Rate:                        0.088450\n",
    "    Replacements:                                850\n",
    "    Total Samples:                              9610\n",
    "    Nested Sampling ln(Z):             -32545.531967\n",
    "    Acceptance Rate:                        0.080121\n",
    "    Replacements:                                900\n",
    "    Total Samples:                             11233\n",
    "    Nested Sampling ln(Z):             -31270.147897\n",
    "    Acceptance Rate:                        0.069674\n",
    "    Replacements:                                950\n",
    "    Total Samples:                             13635\n",
    "    Nested Sampling ln(Z):             -30103.155016\n",
    "    Acceptance Rate:                        0.064201\n",
    "    Replacements:                               1000\n",
    "    Total Samples:                             15576\n",
    "    Nested Sampling ln(Z):             -29365.169148\n",
    "    Acceptance Rate:                        0.058427\n",
    "    Replacements:                               1050\n",
    "    Total Samples:                             17971\n",
    "    Nested Sampling ln(Z):             -28879.280235\n",
    "     ln(ev)=  -28879.280235090871      +/-                       NaN\n",
    "     Total Likelihood Evaluations:        17971\n",
    "     Sampling finished. Exiting MultiNest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook thus far we have not generated sythetic data. However, we did condition on synthetic data. Below we outline how that data was generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The background radiation field incident on the model instrument for the purpose of generating synthetic data was a time-invariant powerlaw spectrum, and was transformed into a count-rate in each output channel using the response matrix for synthetic data generation. We would reproduce this background here by writing a custom subclass as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBackground(xpsi.Background):\n",
    "    \"\"\" The background injected to generate synthetic data. \"\"\"\n",
    "\n",
    "    def __init__(self, num_params, bounds):\n",
    "        super(CustomBackground, self).__init__(num_params, bounds)\n",
    "\n",
    "    def __call__(self, p, energy_edges, phases):\n",
    "        \"\"\" Evaluate the incident background field. \"\"\"\n",
    "        Gamma = p[0]\n",
    "\n",
    "        temp = np.zeros((energy_edges.shape[0] - 1, phases.shape[0]))\n",
    "\n",
    "        temp[:,0] = (energy_edges[1:]**(Gamma + 1.0) - energy_edges[:-1]**(Gamma + 1.0)) / (Gamma + 1.0)\n",
    "\n",
    "        for i in range(phases.shape[0]):\n",
    "            temp[:,i] = temp[:,0]\n",
    "\n",
    "        self.background = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the analytic background is integrated over energy intervals, as required by a ``Pulse`` instance, which would then straightforwardly apply the model instrument response to the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now construct and instantiate a ``background`` object. The base clase ``xpsi.Background`` is inherited from the [ParameterSubspace](parameterSubspace.rst#xpsi.ParameterSubspace.ParameterSubspace) ABC. We therefore need to specify the number of background parameters, and define the hard bounds on those parameters; in this case we have only a single parameter, the powerlaw index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would then instantiate as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = CustomBackground(num_params = 1, bounds = [(-3.0, -1.1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also in need of a simpler data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthesiseData(xpsi.Data):\n",
    "    \"\"\" Custom data container to enable synthesis. \"\"\"\n",
    "    \n",
    "    def __init__(self, first, last, phases):\n",
    "        \"\"\"\n",
    "        :param phase_edges: A :class:`numpy.ndarray` of phase interval edges.\n",
    "\n",
    "        \"\"\"\n",
    "        # Execute parent initialisation code\n",
    "        super(SynthesiseData, self).__init__(first, last)\n",
    "\n",
    "        self._phases = phases\n",
    "\n",
    "    @property\n",
    "    def phases(self):\n",
    "        \"\"\" Get the phase edges. \"\"\"\n",
    "        return self._phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = SynthesiseData(0, 181, phases = np.linspace(0.0, 1.0, 33))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are in need of a ``synthesise`` method, which in this implementation wraps an extension module. Let's check what the extension module offers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xpsi.tools.synthesise import synthesise as _synthesise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_synthesise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesise(self, p,\n",
    "               require_source_counts,\n",
    "               require_background_counts,\n",
    "               name='synthetic',\n",
    "               directory='./data',\n",
    "               **kwargs):\n",
    "        \"\"\" Synthesise data set.\n",
    "\n",
    "        * p[0] = phase shift primary (alias for initial azimuth/phase of photosphere)\n",
    "        * p[1] = phase shift secondary\n",
    "\n",
    "        \"\"\"\n",
    "        self.shift = np.array(p)\n",
    "\n",
    "        self._expected_counts, synthetic = _synthesise(self._data.phases,\n",
    "                                            require_source_counts,\n",
    "                                            require_background_counts,\n",
    "                                            self._pulse,\n",
    "                                            self._phases,\n",
    "                                            self._background.folded_background,\n",
    "                                            self._shift)\n",
    "        try:\n",
    "            if not os.path.isdir(directory):\n",
    "                os.mkdir(directory)\n",
    "        except OSError:\n",
    "            print('Cannot create write directory.')\n",
    "            raise\n",
    "\n",
    "        np.savetxt(os.path.join(directory, name+'_realisation.dat'),\n",
    "                   synthetic,\n",
    "                   fmt = '%u')\n",
    "\n",
    "        self._write(self.expected_counts,\n",
    "                    filename = os.path.join(directory, name+'_expected_hreadable.dat'),\n",
    "                    fmt = '%.8e')\n",
    "\n",
    "        self._write(synthetic,\n",
    "                    filename = os.path.join(directory, name+'_realisation_hreadable.dat'),\n",
    "                    fmt = '%u')\n",
    "\n",
    "def _write(self, counts, filename, fmt):\n",
    "    \"\"\" Write to file in human readable format. \"\"\"\n",
    "\n",
    "    rows = len(self._data.phases) - 1\n",
    "    rows *= self._data.channel_range[1] - self._data.channel_range[0]\n",
    "\n",
    "    phases = self._data.phases[:-1]\n",
    "    array = np.zeros((rows, 3))\n",
    "\n",
    "    for i in range(counts.shape[0]):\n",
    "        for j in range(counts.shape[1]):\n",
    "            array[i*len(phases) + j,:] = i+20, phases[j], counts[i,j]\n",
    "\n",
    "    np.savetxt(filename, array, fmt=['%u', '%.6f'] + [fmt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add unbound methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomPulse.synthesise = synthesise\n",
    "CustomPulse._write = _write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate, and reconfigure the likelihood object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pulse = CustomPulse(tag = 'all',\n",
    "                    num_params = 2,\n",
    "                    bounds = [(-0.25, 0.75), (-0.25, 0.75)],\n",
    "                    data = _data,\n",
    "                    instrument = NICER,\n",
    "                    background = background,\n",
    "                    interstellar = None,\n",
    "                    energies_per_interval = 0.5,\n",
    "                    default_energy_spacing = 'logspace',\n",
    "                    fast_rel_energies_per_interval = 0.5,\n",
    "                    workspace_intervals = 1000,\n",
    "                    adaptive_energies = False,\n",
    "                    store = True,\n",
    "                    epsrel = 1.0e-8,\n",
    "                    epsilon = 1.0e-3,\n",
    "                    sigmas = 10.0)\n",
    "\n",
    "hot.set_phases(num_leaves = 100)\n",
    "likelihood = xpsi.Likelihood(star = star, pulses = pulse, threads=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to synthesise. First we set an environment variable to seed the random number generator being called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GSL_RNG_SEED=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check write path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.2,\n",
    "     1.4,\n",
    "     12.5,\n",
    "     1.25,\n",
    "     1.0,\n",
    "     0.075,\n",
    "     6.2,\n",
    "     math.pi - 1.0,\n",
    "     0.2,\n",
    "     6.0,\n",
    "     -2.0,\n",
    "     0.0,\n",
    "     0.025]\n",
    "\n",
    "likelihood.synthesise(p,\n",
    "                      require_source_counts=2.0e6,\n",
    "                      require_background_counts=2.0e6,\n",
    "                      name='synthetic',\n",
    "                      directory='./data') # SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_one_pulse(np.loadtxt('data/synthetic_realisation.dat', dtype=np.double), _data.phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check we have generated the same count numbers, given the same seed and resolution settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = data.counts-np.loadtxt('data/synthetic_realisation.dat', dtype=np.double)\n",
    "(diff != 0.0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we constructed a model, looked at the sampling interface, and synthesised data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
